{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "\n",
        "This exercise demonstrates a method for estimating surface-level NO2 concentrations using a combination of TEMPO satellite and GEOS-CF model data.\n",
        "\n",
        "**Notebook Author / Affiliation**\n",
        "\n",
        "* Author: Carl Malings / NASA ARSET\n",
        "* This notebook is based on examples from the [ASDC Data and User Services Github](https://github.com/nasa/ASDC_Data_and_User_Services)."
      ],
      "metadata": {
        "id": "ie_Ber64pkVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Package Installation and Setup\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Run the cell below to install the non-standard packages required for this exercise. Since we are overwriting some packages, Colab will ask you to restart your session once the installations have completed.\n",
        "\n",
        "*NOTE: This also includes pyrisg, pydap, and netcdf4 packages, in addition to those used in previous exercises*"
      ],
      "metadata": {
        "id": "1irxs4Va0IQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U harmony-py\n",
        "! pip install cartopy\n",
        "! pip install pyrsig\n",
        "! pip install xarray[io]\n",
        "! pip install -q 'netCDF4<1.6'\n",
        "! pip install pydap"
      ],
      "metadata": {
        "id": "OdBaZPXd0H_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Instructions*\n",
        "\n",
        "* Run the code cell below to import the required packages."
      ],
      "metadata": {
        "id": "z1205WzR3K9w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78NELfmHz4gW"
      },
      "outputs": [],
      "source": [
        "# Downloading TEMPO data\n",
        "import datetime as dt\n",
        "import getpass\n",
        "import os\n",
        "from harmony import BBox, Client, Collection, Request\n",
        "from harmony.config import Environment\n",
        "\n",
        "# Opening TEMPO data files\n",
        "import xarray as xr\n",
        "\n",
        "# Creating graphics\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "import matplotlib.pyplot as plt\n",
        "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
        "from xarray.plot.utils import label_from_attrs\n",
        "\n",
        "# Downloading AirNow data\n",
        "import pyrsig\n",
        "\n",
        "# Working with data tables\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estimate Surface NO2 Concentration from TEMPO and GEOS-CF\n",
        "\n",
        "The first part of this exercise will be to use TEMPO and GEOS-CF data to estimate surface NO2 concentrations for a region and time period of interest."
      ],
      "metadata": {
        "id": "IY9pYsFLqGN9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get TEMPO Level-3 NO2 Data\n",
        "\n",
        "The below code is copied from previous examples of downloading TEMPO data. You will use it to download TEMPO Level-3 NO2 data for a region and time period of inerest. You can choose your own region and time period, or use the information below to follow along.\n",
        "\n",
        "**Region of Interest**: Arizona (latitude 31 to 37, longitude -115 to -108)\n",
        "\n",
        "**Time of Interest**: June 5 to 7, 2024\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Modify the code in the next cells to download the TEMPO Level-3 NO2 data product for the region and time period of interest.\n",
        "\n",
        "* Run the cells in sequence to download the desired TEMPO data.\n",
        "\n",
        "<details>\n",
        "\n",
        "*Hint*: You will need to modify the `RoI`, `Collection id`, `start` and `stop` times.\n",
        "\n",
        "*Hint*: Use [Earthdata Search](https://search.earthdata.nasa.gov/search) to get the Collection id.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "pBXn2JTq0Isv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Authenticate EarthData credentials*"
      ],
      "metadata": {
        "id": "_1DWkOsBS3Iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "username = input(\"Username:\")\n",
        "\n",
        "harmony_client = Client(env=Environment.PROD, auth=(username, getpass.getpass()))"
      ],
      "metadata": {
        "id": "G3yW37_nS2gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Build the request*"
      ],
      "metadata": {
        "id": "6utEczoTSJo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This list will save the bounding box limits for later use:\n",
        "RoI = [-180, -90, 180, 90]\n",
        "\n",
        "# Structure the request:\n",
        "request = Request(\n",
        "    collection=Collection(id='input_collection_id_here'),\n",
        "    temporal={\n",
        "        'start': dt.datetime(2001, 1, 1),\n",
        "        'stop': dt.datetime(2001, 1, 2)\n",
        "    },\n",
        "    spatial=BBox(RoI[0], RoI[1], RoI[2], RoI[3]),\n",
        ")\n",
        "\n",
        "# Check the request is valid:\n",
        "request.is_valid()"
      ],
      "metadata": {
        "id": "HvvCgc3L2qOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Submit and monitor the request*"
      ],
      "metadata": {
        "id": "xxKk-W2XSFE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_id = harmony_client.submit(request)\n",
        "print(f\"jobID = {job_id}\")\n",
        "\n",
        "harmony_client.wait_for_processing(job_id, show_progress=True)"
      ],
      "metadata": {
        "id": "bd5sdK4B3sq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Download the results*"
      ],
      "metadata": {
        "id": "RwiabuNlSC-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "download_dir = os.path.expanduser(\"~/tempo_data_surface_aq_exercise\")\n",
        "os.makedirs(download_dir, exist_ok=True)\n",
        "\n",
        "results = harmony_client.download_all(job_id, directory=download_dir)\n",
        "all_results_stored = [f.result() for f in results]\n",
        "\n",
        "print(f\"Number of files: {len(all_results_stored)}\")"
      ],
      "metadata": {
        "id": "O_9NQeeA31QL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Open the files and combine into a single Dataset*\n",
        "\n",
        "<details>\n",
        "\n",
        "*Hint:* This is a new step, which combines data from mulitple files into a single varaible called a Dataset. Look at the dimensions of the dataset; notice how there is a \"time\" dimension, with the length of that dimension equal to the number of files.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "T3sxCjy0R9UG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create empty lists for the TEMPO NO2 and QC data:\n",
        "data_list_no2 = []\n",
        "data_list_qc = []\n",
        "data_list_clouds = []\n",
        "# Loop through the result files:\n",
        "for result_file in sorted(all_results_stored):\n",
        "    # For each file, add the NO2 or QC data from that file to the appropriate list:\n",
        "    data_list_no2 += [xr.open_datatree(result_file)['product/vertical_column_troposphere']]\n",
        "    data_list_qc += [xr.open_datatree(result_file)['product/main_data_quality_flag']]\n",
        "    data_list_clouds += [xr.open_datatree(result_file)['support_data/eff_cloud_fraction']]\n",
        "\n",
        "# Concatenate each list into a Dataset along the time dimenion:\n",
        "tempo_data_no2 = xr.concat(data_list_no2,dim='time')\n",
        "tempo_data_qc = xr.concat(data_list_qc,dim='time')\n",
        "tempo_data_clouds = xr.concat(data_list_clouds,dim='time')\n",
        "\n",
        "# Merge both Datasets together:\n",
        "tempo_data = xr.merge([tempo_data_no2,tempo_data_qc,tempo_data_clouds])\n",
        "\n",
        "# Examine the result:\n",
        "tempo_data"
      ],
      "metadata": {
        "id": "EpAOxM814iFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Apply quality control*\n",
        "\n",
        "<details>\n",
        "\n",
        "In this excercise, we will filter using the main data quality flag, accepting only Normal quality data, and by effective cloud fraction, accepting pixels with effective cloud fraction less than 0.2.\n",
        "\n",
        "*Hint:* TEMPO quality flags are:\n",
        "\n",
        "* `0` = Normal quality (use for analysis)\n",
        "\n",
        "* `1` = Suspect quality (use with caution)\n",
        "\n",
        "* `2` = Bad quality (exclude from analysis)\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "eLLRlJQlzwyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filter_qa = tempo_data['main_data_quality_flag'] == 0\n",
        "filter_clouds = tempo_data['eff_cloud_fraction'] < 0.2\n",
        "\n",
        "tempo_data = tempo_data.where(filter_qa & filter_clouds).squeeze()"
      ],
      "metadata": {
        "id": "LobZBeIFzxK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get GEOS-CF Model NO2 Data"
      ],
      "metadata": {
        "id": "DhjQgCLoRrTP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a Function to get GEOS-CF Data**\n",
        "\n",
        "To estimate the surface-level NO2 from the TEMPO tropospheric column NO2, we are going to use the model surface-to-column ratio method. In order to apply this method, we need to get the tropospheric column and surface NO2 concentrations for the same region from a model. We will be using the [NASA GEOS-CF](https://gmao.gsfc.nasa.gov/weather_prediction/GEOS-CF/) model outputs for this excercise.\n",
        "\n",
        "We have created a function called `append_GEOSCF_NO2_to_dataset` below which takes as input a data array with latitude, longitude, and time dimensions, and outputs the same data, but with two additional varaibles: the GEOS-CF surface-level NO2, called `geoscf_surface_no2`, and the GEOS-CF tropospheric column NO2, called `geoscf_vertical_column_troposphere_no2`. The function also outputs the GEOS-CF data it has downloaded for the region and time period of interest, for potential later use. If you are curious, you can look into the details of what the function is doing.\n",
        "\n",
        "*Instructions*\n",
        "* Run the next cell to create the function `append_GEOSCF_NO2_to_dataset`."
      ],
      "metadata": {
        "id": "LyLFIzkK6mpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def append_GEOSCF_NO2_to_dataset(input_array):\n",
        "    # This function is designed to append surface-level and tropospheric column NO2 values from the GEOS-CF model to an input dataset.\n",
        "    # Inputs:\n",
        "    #  - input_array: a three-dimensional xarray Dataset or DataArray object with the dimensions 'latitude', 'longitude', and 'time'\n",
        "    # Outputs:\n",
        "    #  - output_array: a three-dimensional xarray Dataset, the same as the input, augmented with with two additional varaibles from GEOS-CF: the surface-level NO2 (geoscf_surface_no2) and the tropospheric column NO2 (geoscf_vertical_column_troposphere_no2)\n",
        "    #\n",
        "    # NOTE:\n",
        "    # This code accesses GEOS-CF data using the GMAP OpeNDAP service:\n",
        "    # https://opendap.nccs.nasa.gov/dods/gmao/geos-cf\n",
        "    #\n",
        "    # Upcoming changes to GEOS-CF versions, variable names, and file structure may cause this access method to no longer function.\n",
        "    #\n",
        "    # Please visit the GEOS-CF Data Access webpage for more information:\n",
        "    # https://gmao.gsfc.nasa.gov/weather_prediction/GEOS-CF/data_access/\n",
        "\n",
        "    # Convert the input to a dataset, if it is not already:\n",
        "    if type(input_array) != xr.Dataset:\n",
        "      try:\n",
        "        input_array = xr.Dataset({input_array.name:input_array})\n",
        "      except:\n",
        "        print('ERROR: input data type can not be converted to a dataset.')\n",
        "\n",
        "    # Define the maximum and minimum dimensions of the input data to get the extent of interest:\n",
        "    min_lat = input_array.latitude.values.min() - 0.25 # get the minimum latitude from the input dataset, subtract 0.25 for a buffer\n",
        "    max_lat = input_array.latitude.values.max() + 0.25 # get the maximum latitude from the input dataset, add 0.25 for a buffer\n",
        "    min_lon = input_array.longitude.values.min() - 0.25 # get the minimum longitude from the input dataset, subtract 0.25 for a buffer\n",
        "    max_lon = input_array.longitude.values.max() + 0.25 # get the maximum longitude from the input dataset, add 0.25 for a buffer\n",
        "    min_time = input_array.time.values.min() - np.timedelta64(1,'h') # get the minimum time from the input dataset, subtract 1 hour for a buffer\n",
        "    max_time = input_array.time.values.max() + np.timedelta64(1,'h') # get the maximum time from the input dataset, add 1 hour for a buffer\n",
        "\n",
        "    # Query the GEOS-CF surface-level composition dataset for NO2 for the area and time above:\n",
        "    geoscf_opendap_aqc = 'https://opendap.nccs.nasa.gov/dods/gmao/geos-cf/assim/aqc_tavg_1hr_g1440x721_v1' # specify the OpeNDAP location for the data\n",
        "    geoscf_surface_no2 = xr.open_dataset(geoscf_opendap_aqc).loc[{'time':slice(min_time,max_time),'lat':slice(min_lat,max_lat),'lon':slice(min_lon,max_lon)}]['no2'].mean('lev') # access NO2 data for the time and location\n",
        "    geoscf_surface_no2_renamed = geoscf_surface_no2.rename({'lat':'latitude','lon':'longitude'}) # rename the data dimensions to match the input file dimensions\n",
        "    geoscf_surface_no2_rescaled = geoscf_surface_no2_renamed * 1e9 # rescale NO2 units from mol per mol to ppb\n",
        "    geoscf_surface_no2_at_input = geoscf_surface_no2_rescaled.interp_like(input_array,method='nearest') # interpolate the GEOS-CF grid to the input dataset grid\n",
        "\n",
        "    # Query the GEOS-CF column composition dataset for tropospheric column NO2 for the area and time above:\n",
        "    geoscf_opendap_xgc = 'https://opendap.nccs.nasa.gov/dods/gmao/geos-cf/assim/xgc_tavg_1hr_g1440x721_x1' # specify the OpeNDAP location for the data\n",
        "    geoscf_tropcol_no2 = xr.open_dataset(geoscf_opendap_xgc).loc[{'time':slice(min_time,max_time),'lat':slice(min_lat,max_lat),'lon':slice(min_lon,max_lon)}]['tropcol_no2'] # access column NO2 data for the time and location\n",
        "    geoscf_tropcol_no2_renamed = geoscf_tropcol_no2.rename({'lat':'latitude','lon':'longitude'}) # rename the data dimensions to match the input file dimensions\n",
        "    geoscf_tropcol_no2_rescaled = geoscf_tropcol_no2_renamed * 1e15 # rescale units from 1.0e15 molec cm-2 to molec cm-2\n",
        "    geoscf_tropcol_no2_at_input = geoscf_tropcol_no2_rescaled.interp_like(input_array,method='nearest') # interpolate the GEOS-CF grid to the input dataset grid\n",
        "\n",
        "    # Add the data into the output:\n",
        "    output_array = input_array\n",
        "    output_array['geoscf_surface_no2'] = geoscf_surface_no2_at_input\n",
        "    output_array['geoscf_vertical_column_troposphere_no2'] = geoscf_tropcol_no2_at_input\n",
        "\n",
        "    # Return the GEOS-CF Data as well:\n",
        "    geoscf_dataset = xr.merge([geoscf_surface_no2_rescaled,geoscf_tropcol_no2_rescaled])\n",
        "\n",
        "    # Return the output:\n",
        "    return output_array,geoscf_dataset"
      ],
      "metadata": {
        "id": "iurKuvvc6rdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get GEOS-CF data for the region and time of interest**\n",
        "\n",
        "Using the function you just defined, you can get the necessary GEOS-CF data to compute surface-to-column NO2 ratios.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Apply the `append_GEOSCF_NO2_to_dataset` function to your level 3 TEMPO dataset from above to append the GEOS-CF NO2 data.\n",
        "\n",
        "<details>\n",
        "\n",
        "*Hint*: to apply this function, use the syntax `output1,output2 = function_name(input)`\n",
        "\n",
        "*Hint*: The function has two outputs: the first is the one we want now (the GEOS-CF information appended into the level 3 TEMPO dataset), the second is some other useful information from GEOS-CF we will use later.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "ADgp7vCPOh-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here"
      ],
      "metadata": {
        "id": "lGOAWkks-KjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute the Surface-to-Column Ratio and Estimate Surface-level NO2"
      ],
      "metadata": {
        "id": "dXEKywxDRxRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Now, you have all the data you need to calculate the GEOS-CF surface-to-column ratio and multiply this by the tropospheric column NO2 from TEMPO to get an estimate of surface-level NO2.  \n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Calculate the surface-to-column NO2 ratio from the GEOS-CF varaibles `geoscf_surface_no2` and `geoscf_vertical_column_troposphere_no2` in your dataset.\n",
        "\n",
        "* Multiply this ratio by the TEMPO tropospheric column NO2 to get the estimated surface NO2.\n",
        "\n",
        "<details>\n",
        "\n",
        "*Hint*: You can do math with variables in a dataset and define the results as new variables in the same dataset. For example:\n",
        "\n",
        "```dataset['variable 1 times variable 2'] = dataset['variable 1'] * dataset['variable 2']```\n",
        "\n",
        "```dataset['variable 1 divided by variable 2'] = dataset['variable 1'] / dataset['variable 2']```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "sE20R_dDPWor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here"
      ],
      "metadata": {
        "id": "8UxkXdcpRRn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Maps of Surface-level NO2 Estimates\n",
        "\n",
        "The code below is taken from earlier plotting examples, with slight modifications.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Examine the code example below and determine where it is trying to get the surface NO2 estimates from.\n",
        "\n",
        "* Replace this with the appropriate dataset from your code.\n",
        "\n",
        "* Run the cell and check the output.\n",
        "\n",
        "* Try picking different timestamps to plot and examining the output.\n",
        "\n",
        "<details>\n",
        "\n",
        "*Hint*: The code example assumes that `tempo_data_with_geoscf['surface_no2_estimate']` is the source of the surface-estiamted NO2 data.\n",
        "\n",
        "*Hint*: There is a set of code at the bottom you can try to uncomment and modify to plot all timestamps in a loop.\n",
        "\n",
        "</details>\n"
      ],
      "metadata": {
        "id": "K0up-hojRZwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_proj = ccrs.PlateCarree()\n",
        "\n",
        "def make_nice_map(axis):\n",
        "    axis.add_feature(cfeature.STATES.with_scale('50m'), edgecolor=\"black\", linewidth=0.5)\n",
        "    roads = cfeature.NaturalEarthFeature(\n",
        "        category=\"cultural\",\n",
        "        name=\"roads\",\n",
        "        scale=\"10m\",\n",
        "        facecolor=\"none\",\n",
        "    )\n",
        "    axis.add_feature(roads, linestyle=\"--\", edgecolor=\"grey\", linewidth=0.5)\n",
        "    axis.coastlines(resolution=\"50m\", color=\"black\", linewidth=1.0)\n",
        "\n",
        "    axis.set_extent([RoI[0], RoI[2], RoI[1], RoI[3]], crs=data_proj)\n",
        "    grid = axis.gridlines(draw_labels=[\"left\", \"bottom\"], dms=True)\n",
        "    grid.xformatter = LONGITUDE_FORMATTER\n",
        "    grid.yformatter = LATITUDE_FORMATTER\n",
        "\n",
        "# List the potential timestamps to visualize\n",
        "print(tempo_data_with_geoscf['surface_no2_estimate'].time.values)\n",
        "\n",
        "# Select the data from a timestamp\n",
        "timestamp = tempo_data_with_geoscf['surface_no2_estimate'].time.values[1] # e.g., pick the second time in the list\n",
        "data_to_plot = tempo_data_with_geoscf['surface_no2_estimate'].sel(time=timestamp)\n",
        "\n",
        "# Plot the data on a map\n",
        "fig, ax = plt.subplots(figsize=(10, 6), subplot_kw={\"projection\": data_proj})\n",
        "\n",
        "make_nice_map(ax)\n",
        "\n",
        "ax.set_title(timestamp)\n",
        "\n",
        "data_to_plot.plot(\n",
        "    ax=ax, # axis to add plot to\n",
        "    cmap=plt.get_cmap('Blues'), # color scale\n",
        "    vmin=0, # minimum value\n",
        "    vmax=25, # maximum value\n",
        "    cbar_kwargs={'label':'Surface $NO_2$ Estimate [ppb]'} # set colorbar label\n",
        ")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Uncomment the code below to plot all timestamps:\n",
        "#fig, axs = plt.subplots(\n",
        "#    nrows=len(tempo_data_with_geoscf['surface_no2_estimate'].time.values),\n",
        "#    sharex=True,\n",
        "#    figsize=(5, 50),\n",
        "#    gridspec_kw=dict(hspace=0.5),\n",
        "#    subplot_kw={\"projection\": data_proj},\n",
        "#)\n",
        "\n",
        "#for i,timestamp in enumerate(tempo_data_with_geoscf['surface_no2_estimate'].time.values):\n",
        "#    Var = tempo_data_with_geoscf['surface_no2_estimate'].sel(time=timestamp)\n",
        "#    make_nice_map(axs[i])\n",
        "#    Var.plot(ax=axs[i],cmap=plt.get_cmap('Blues'),vmin=0,vmax=25,cbar_kwargs={'label':'$NO_2$ [ppb]'})\n",
        "#    axs[i].set_title(timestamp, fontsize=8)\n",
        "\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "NlpqW3IeMPqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare with AirNow NO2 Monitor Data\n",
        "\n",
        "We will now compare the TEMPO-derived NO2 estimates with monitored NO2 data from AirNow. This will allow us to begin assessing the quality of the estimate."
      ],
      "metadata": {
        "id": "e5GEKvu3cdrh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use pyrsig to download AirNow NO2\n",
        "\n",
        "We will use the [pyrsig package](https://barronh.github.io/pyrsig/) to easily bring the AirNow NO2 data into python. Below is a template for how a query is structured and submitted to pyrsig. The result will be a data table with the NO2 data, timestamps, and station information.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Modify the template to have the approrpiate start end and dates.\n",
        "\n",
        "* Modify the template to have the appropriate bounding box for the region of interest.\n",
        "\n",
        "* Run the cell to examine the output table."
      ],
      "metadata": {
        "id": "7c7NvIAEcgQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the query for pyrisg:\n",
        "api = pyrsig.RsigApi(bdate=\"2001-01-01\", # start date of the query, in the format \"YYYY-MM-DD\"\n",
        "                     edate=\"2001-01-02\", # end date of the query, in the format \"YYY-MM-DD\"\n",
        "                     bbox=(-180,-90,180,90), # bounding box for the query, in the format (minimum_longitude,minimum_latitude,maximum_longitude,maximum_latitude)\n",
        "                     workdir=download_dir, # temporary directory to store the downloaded data\n",
        "                     gridfit=True) # data are not being re-aligned to a grid\n",
        "airnowkey = \"airnow.no2\" # this is the pyrsig code to specify NO2 data from AirNow\n",
        "\n",
        "# Execute the query to download the data:\n",
        "airnow_data = api.to_dataframe(airnowkey, unit_keys=False, parse_dates=True)\n",
        "\n",
        "# Examine the resulting table:\n",
        "airnow_data"
      ],
      "metadata": {
        "id": "V73G4YMDdNs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract TEMPO-estimated NO2 values at monitor locations and sampling times\n",
        "\n",
        "For comparing the data, will will add our TEMPO-estimated NO2 values (as well as the model estiamtes from GEOS-CF) into this table. A code loop is set up to do this below, but it assumes the estimated surface NO2 concentrations from TEMPO are in a specifically named dataset which might not exist in your run of the code.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Examine the code example below and determine where it is trying to get the surface NO2 estimates from.\n",
        "\n",
        "* Replace this with the appropriate dataset from your code.\n",
        "\n",
        "* Run the cell and check the output.\n",
        "\n",
        "<details>\n",
        "\n",
        "*Hint*: The code example assumes that `tempo_data_with_geoscf['surface_no2_estimate']` is the source of the surface-estimated NO2 data.\n",
        "\n",
        "*Hint*: The code example also assumes that `geoscf_dataset` was the second output from the `append_GEOSCF_NO2_to_dataset` function above.\n",
        "\n",
        "*Hint*: This code also converts the timestamps into local time, using an assumed time zone (MST). Be sure to change this time zone if you are looking in a different area.\n"
      ],
      "metadata": {
        "id": "M_7kzYNOcjil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new column in the table to store the TEMPO-estimated NO2; initialize it to NaN values using np.nan\n",
        "airnow_data['no2_TEMPO_ESTIMATE'] = np.nan\n",
        "\n",
        "# For convenience, we will also add a column time column:\n",
        "airnow_data['local_time'] = np.nan\n",
        "\n",
        "# Loop through the rows of the table:\n",
        "for row in range(len(airnow_data)):\n",
        "  site_latitude = airnow_data['LATITUDE'][row] # latitude of the monitor\n",
        "  site_longitude = airnow_data['LONGITUDE'][row] # longitude of the monitor\n",
        "  sample_start_time = np.datetime64(airnow_data['Timestamp'][row][0:19]) # timestamp of the row, converted to a numpy datetime object for compatibility with xarray\n",
        "  sample_end_time = sample_start_time + np.timedelta64(1,'h') # increment the timestamp by one hour, to account for the end of the one-hour sample\n",
        "\n",
        "  # This line interpolates the array of estimated surface NO2 to the latitude and longitude of the monitor, selects times within the sampling time interval, and returns the average:\n",
        "  no2_estimate_tempo = tempo_data_with_geoscf['surface_no2_estimate'].interp(latitude=site_latitude,longitude=site_longitude).sel(time=slice(sample_start_time,sample_end_time)).mean('time').values\n",
        "\n",
        "  # Store this estimated NO2 value into the appropriate row and column of the table:\n",
        "  airnow_data.loc[row,'no2_TEMPO_ESTIMATE'] = no2_estimate_tempo\n",
        "\n",
        "  # These lines do the same for the GEOS-CF NO2:\n",
        "  no2_estimate_geoscf = geoscf_dataset['no2'].interp(latitude=site_latitude,longitude=site_longitude).sel(time=slice(sample_start_time,sample_end_time)).mean('time').values\n",
        "  airnow_data.loc[row,'no2_GEOSCF_ESTIMATE'] = no2_estimate_geoscf\n",
        "\n",
        "  # Convert the timestamp to local time for convenience and store the value in the appropriate row and column of the table:\n",
        "  # Note that the tz input to the tz_convert function is the local time zone.\n",
        "  airnow_data.loc[row,'local_time'] = airnow_data['time'][row].tz_convert(tz='MST')\n",
        "\n",
        "# Examine the resulting table:\n",
        "airnow_data"
      ],
      "metadata": {
        "id": "xqrAaJr1eZDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time Series Comparison Plot\n",
        "\n",
        "We will now compare the TEMPO-estimated NO2 with the measured NO2 at a surface monitor station, as well as the GEOS-CF model NO2. Use the code template below to generate a time-series plot comparing these values for a single site.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Run the cell to generate the plot.\n",
        "\n",
        "* Try changing the site name to look at different sites.\n",
        "\n",
        "* Note which sites the estimates seem to be doing well at, and which sites they are doing poorly.\n",
        "\n"
      ],
      "metadata": {
        "id": "y05J1kpkcvWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list available sites:\n",
        "print(np.unique(airnow_data['SITE_NAME']))\n",
        "\n",
        "# choose a site:\n",
        "site = '                          840040130019;42602'\n",
        "airnow_data_site = airnow_data.where(airnow_data['SITE_NAME'] == site).dropna(how='all')\n",
        "\n",
        "# Create a plot:\n",
        "figure, axis = plt.subplots()\n",
        "axis.plot(airnow_data_site['local_time'],airnow_data_site['no2'],color='orange',label='Monitor (measurement)')\n",
        "axis.plot(airnow_data_site['local_time'],airnow_data_site['no2_TEMPO_ESTIMATE'],color='blue',label='TEMPO (estimate)')\n",
        "axis.plot(airnow_data_site['local_time'],airnow_data_site['no2_GEOSCF_ESTIMATE'],color='red',label='GEOS-CF (estimate)')\n",
        "plt.legend()\n",
        "plt.xlabel('local time')\n",
        "plt.ylabel('$NO_2$ [ppb]')\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('site id: {}'.format(site.replace(' ','')))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xBxSs5usiM8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Map Comparison Plot\n",
        "\n",
        "Finally, we will create a map of the TEMPO-derived NO2 estimates and overlay the surface NO2 monitor data as points. The code example below should generate this plot, but again, it assumes the estimated surface NO2 concentrations from TEMPO are in a specifically named dataset which might not exist in your run of the code.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Examine the code below to see where it is getting its TEMPO-derived NO2 estimates from, and replace this with the correct dataset from your run of the code.\n",
        "\n",
        "* Once you have gotten the example to run successfully, try changing the hour of interest and re-running. See if the spatial patterns of NO2 estimated by TEMPO seem to agree with the pattern of surface monitor data.\n",
        "\n",
        "<details>\n",
        "\n",
        "*Hint*: Try copying subsets of the code into a new cell to run it incrementally, and see where the errors are coming from. Put the name of a variable in a cell by itself and run that cell to see what the variable looks like."
      ],
      "metadata": {
        "id": "wCsWa5KzcrbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an hour of interest for plotting:\n",
        "hour_of_interest = pd.Timestamp('2024-06-05 07:00:00',tz='MST')\n",
        "\n",
        "# Get the start and end timestamps, in UTC and in numpy format for xarray compatibility:\n",
        "plot_hour_start_utc = np.datetime64(hour_of_interest.tz_convert(tz='UTC'))\n",
        "plot_hour_end_utc = plot_hour_start_utc + np.timedelta64(1,'h')\n",
        "\n",
        "# Select the surface NO2 estimate data corresponding to the time of interest:\n",
        "tempo_no2_estimate_to_plot = tempo_data_with_geoscf['surface_no2_estimate'].sel(time=slice(plot_hour_start_utc,plot_hour_end_utc)).mean('time')\n",
        "\n",
        "# Select the AirNow NO2 data to plot:\n",
        "airnow_no2_to_plot = airnow_data.where(airnow_data['local_time'] == hour_of_interest).dropna(how='all')\n",
        "\n",
        "# Make the plot:\n",
        "figure, axis = plt.subplots(\n",
        "    subplot_kw={\"projection\": data_proj},\n",
        ")\n",
        "make_nice_map(axis)\n",
        "tempo_no2_estimate_to_plot.plot(ax=axis,cmap=plt.get_cmap('Blues'),vmin=0,vmax=25,cbar_kwargs={'label':'NO2 [ppb]'})\n",
        "axis.scatter(airnow_no2_to_plot['LONGITUDE'],airnow_no2_to_plot['LATITUDE'],s=20,c=airnow_no2_to_plot['no2'],cmap=plt.get_cmap('Blues'),vmin=0,vmax=25,edgecolors='black')\n",
        "axis.set_title('local time: {}'.format(hour_of_interest))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gtY-LKeKn4n2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bonus: Create Time-of-Day Average Map Plots\n",
        "\n",
        "It may be useful to aggregate TEMPO data across multiple days to achieve a more robust estimate. However, to retain the benefit of TEMPO's hourly observations, this aggregation might be done for specific times of day. Below is a code example showing how this can be done. Note that we are only aggregating data for a couple of days in this example; aggregating across weeks or months can yield a more robust estimate.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Modify the code example below to use the correct dataset where you stored your TEMPO-estimated surface NO2.\n",
        "\n",
        "* Run the cell to generate a plot of surface estimated NO2, averaged across the time period of interest but at a specific time of day. Averaged NO2 from AirNow monitors at the same time of day are overlaid on this map.\n",
        "\n",
        "* Change the time of day of interest to examine other times of day.\n",
        "\n",
        "<details>\n",
        "\n",
        "*Hint*: The code example assumes the the surface-estimated NO2 from TEMPO are contained in the `tempo_data_with_geoscf` dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "wnpCywz0cVkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a local-time-of-day coordinate for the local time of day for the TEMPO dataset:\n",
        "local_times = [pd.Timestamp(timestamp,tz='UTC').tz_convert(tz='MST') for timestamp in tempo_data_with_geoscf.time.values]\n",
        "local_times_of_day = [local_time.hour for local_time in local_times]\n",
        "\n",
        "tempo_data_with_geoscf = tempo_data_with_geoscf.assign_coords({'local_time_of_day':('time',local_times_of_day)})\n",
        "\n",
        "tempo_data_with_geoscf_time_of_day_average = tempo_data_with_geoscf.groupby('local_time_of_day').mean('time')\n",
        "\n",
        "# Repeat the process for the AirNow data table:\n",
        "airnow_data['local_time_of_day'] = [timestamp.hour for timestamp in airnow_data['local_time']]\n",
        "\n",
        "airnow_data_time_of_day_average = airnow_data.groupby(['SITE_NAME','local_time_of_day']).mean('time').reset_index()\n",
        "\n",
        "# Plot the results for a specific time of day:\n",
        "time_of_day_to_plot = 7\n",
        "\n",
        "tempo_no2_estimate_to_plot = tempo_data_with_geoscf_time_of_day_average.sel({'local_time_of_day':time_of_day_to_plot})['surface_no2_estimate']\n",
        "airnow_no2_to_plot = airnow_data_time_of_day_average.where(airnow_data_time_of_day_average['local_time_of_day']==time_of_day_to_plot).dropna(how='all')\n",
        "\n",
        "figure, axis = plt.subplots(\n",
        "    subplot_kw={\"projection\": data_proj},\n",
        ")\n",
        "make_nice_map(axis)\n",
        "tempo_no2_estimate_to_plot.plot(ax=axis,cmap=plt.get_cmap('Blues'),vmin=0,vmax=25,cbar_kwargs={'label':'NO2 [ppb]'})\n",
        "axis.scatter(airnow_no2_to_plot['LONGITUDE'],airnow_no2_to_plot['LATITUDE'],s=20,c=airnow_no2_to_plot['no2'],cmap=plt.get_cmap('Blues'),vmin=0,vmax=25,edgecolors='black')\n",
        "axis.set_title('{}:00 local time'.format(time_of_day_to_plot))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xImUtKyayOZp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}