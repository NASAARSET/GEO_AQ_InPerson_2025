{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "\n",
        "This exercise demonstrates how TEMPO data can be used to track and assess ozone precursors and ozone formation potential, in support of assessing ozone exceedances.\n",
        "\n",
        "**Notebook Author / Affiliation**\n",
        "\n",
        "* Author: Carl Malings / NASA ARSET\n",
        "* This notebook is based on examples from the [ASDC Data and User Services Github](https://github.com/nasa/ASDC_Data_and_User_Services)."
      ],
      "metadata": {
        "id": "ie_Ber64pkVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Package Installation and Setup\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Run the cell below to install the non-standard packages required for this exercise.\n",
        "\n",
        "*NOTE: This also includes the pyrisg package, in addition to those used in previous exercises*"
      ],
      "metadata": {
        "id": "1irxs4Va0IQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet harmony-py cartopy pyrsig"
      ],
      "metadata": {
        "id": "OdBaZPXd0H_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Instructions*\n",
        "\n",
        "* Run the code cell below to import the required packages."
      ],
      "metadata": {
        "id": "z1205WzR3K9w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78NELfmHz4gW"
      },
      "outputs": [],
      "source": [
        "# Downloading TEMPO data\n",
        "import datetime as dt\n",
        "import getpass\n",
        "import os\n",
        "from harmony import BBox, Client, Collection, Request\n",
        "from harmony.config import Environment\n",
        "\n",
        "# Opening TEMPO data files\n",
        "import xarray as xr\n",
        "\n",
        "# Creating graphics\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "import matplotlib.pyplot as plt\n",
        "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
        "from xarray.plot.utils import label_from_attrs\n",
        "\n",
        "# Downloading AirNow data\n",
        "import pyrsig\n",
        "\n",
        "# Working with data tables\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download TEMPO NO2 and HCHO Data\n",
        "\n",
        "The first part of this exercise will be to download the TEMPO NO2 and HCHO data for the region and time period of interest.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Run the cell below and enter your Earthdata credentials to prepare for data downloading"
      ],
      "metadata": {
        "id": "IY9pYsFLqGN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "username = input(\"Username:\")\n",
        "\n",
        "harmony_client = Client(env=Environment.PROD, auth=(username, getpass.getpass()))"
      ],
      "metadata": {
        "id": "G3yW37_nS2gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get TEMPO Level-3 NO2 Data\n",
        "\n",
        "The below code is copied from previous examples of downloading TEMPO data. You will use it to download TEMPO Level-3 NO2 data for a region and time period of inerest.\n",
        "\n",
        "**Region of Interest**: Colorado Front Range (latitude 38 to 41, longitude -106 to -103)\n",
        "\n",
        "**Time of Interest**: July 27 to 30, 2024\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Modify the code in the next cells to download the TEMPO Level-3 NO2 data product for the region and time period of interest.\n",
        "\n",
        "* Run the cells in sequence to download the desired TEMPO data.\n",
        "\n",
        "<details>\n",
        "\n",
        "*Hint*: You will need to modify the `RoI`, `Collection id`, `start` and `stop` times.\n",
        "\n",
        "*Hint*: Use [Earthdata Search](https://search.earthdata.nasa.gov/search) to get the Collection id.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "pBXn2JTq0Isv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Build the request*"
      ],
      "metadata": {
        "id": "6utEczoTSJo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This list will save the bounding box limits for later use:\n",
        "RoI = [-180, -90, 180, 90]\n",
        "\n",
        "# Structure the request:\n",
        "request_no2 = Request(\n",
        "    collection=Collection(id='TEMPO L3 NO2 Collection ID'),\n",
        "    temporal={\n",
        "        'start': dt.datetime(2001, 1, 1),\n",
        "        'stop': dt.datetime(2001, 1, 2)\n",
        "    },\n",
        "    spatial=BBox(RoI[0], RoI[1], RoI[2], RoI[3]),\n",
        ")\n",
        "\n",
        "# Check the request is valid:\n",
        "request_no2.is_valid()"
      ],
      "metadata": {
        "id": "HvvCgc3L2qOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Submit and monitor the request*"
      ],
      "metadata": {
        "id": "xxKk-W2XSFE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_id_no2 = harmony_client.submit(request_no2)\n",
        "print(f\"jobID = {job_id_no2}\")\n",
        "\n",
        "harmony_client.wait_for_processing(job_id_no2, show_progress=True)"
      ],
      "metadata": {
        "id": "bd5sdK4B3sq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Download the results*"
      ],
      "metadata": {
        "id": "RwiabuNlSC-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "download_dir = os.path.expanduser(\"~/tempo_data_ozone_precursor_exercise\")\n",
        "os.makedirs(download_dir, exist_ok=True)\n",
        "\n",
        "results_no2 = harmony_client.download_all(job_id_no2, directory=download_dir)\n",
        "all_results_stored_no2 = [f.result() for f in results_no2]\n",
        "\n",
        "print(f\"Number of files: {len(all_results_stored_no2)}\")"
      ],
      "metadata": {
        "id": "O_9NQeeA31QL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Open the files and combine into a single Dataset*\n",
        "\n",
        "<details>\n",
        "\n",
        "Note that there is a slightly different structure to this code than seen in previous examples. The dictionary `variables_to_keep_and_rename` provides a complete list of the variables to keep and the new names they will be assigned. This makes it more straightforward to change what variables are kept, so that the same code can be re-used more easily for the other TEMPO products.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "OOvztnNRbLF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define which variables to keep and rename:\n",
        "variables_to_keep_and_rename = {'product/vertical_column_troposphere':'no2_vertical_column_troposphere',\n",
        "                                'product/main_data_quality_flag':'no2_qc_flag',\n",
        "                                'geolocation/solar_zenith_angle':'no2_sza',\n",
        "                                'support_data/eff_cloud_fraction':'no2_cloud_fraction'\n",
        "                                }\n",
        "\n",
        "# Create a dictionary to store the data:\n",
        "data_dictionary = {variable:[] for variable in variables_to_keep_and_rename.keys()}\n",
        "\n",
        "# Loop through the result files:\n",
        "for result_file in sorted(all_results_stored_no2):\n",
        "    # Loop throuch variables:\n",
        "    for variable in variables_to_keep_and_rename.keys():\n",
        "        # For each file and variable, add the data from that file to the appropriate list in the dictionary:\n",
        "        data_dictionary[variable] += [xr.open_datatree(result_file)[variable]]\n",
        "\n",
        "# Concatenate each list into a Dataset along the time dimenion:\n",
        "for variable in variables_to_keep_and_rename.keys():\n",
        "    data_dictionary[variable] = xr.concat(data_dictionary[variable],dim='time')\n",
        "\n",
        "# Merge the Datasets together:\n",
        "tempo_data_no2 = xr.merge([data_dictionary[variable] for variable in variables_to_keep_and_rename.keys()])\n",
        "\n",
        "# Rename the variables\n",
        "tempo_data_no2 = tempo_data_no2.rename({variable.split('/')[1]:variables_to_keep_and_rename[variable] for variable in variables_to_keep_and_rename.keys()})\n",
        "\n",
        "# Examine the result:\n",
        "tempo_data_no2"
      ],
      "metadata": {
        "id": "r3mYG4UgbOZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Apply quality control*\n",
        "\n",
        "<details>\n",
        "\n",
        "For this exercise, we will accept Suspect data, and also filter by Solar Zenith Angle (accepting values less than 80) and Cloud Fraction (accepting values less than 0.2)\n",
        "\n",
        "*Hint:* TEMPO quality flags are:\n",
        "\n",
        "* `0` = Normal quality (use for analysis)\n",
        "\n",
        "* `1` = Suspect quality (use with caution)\n",
        "\n",
        "* `2` = Bad quality (exclude from analysis)\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "TYcIgCxDbr2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filter_qa = tempo_data_no2['no2_qc_flag'] <= 1\n",
        "filter_sza = tempo_data_no2['no2_sza'] < 80\n",
        "filter_cf = tempo_data_no2['no2_cloud_fraction'] < 0.2\n",
        "\n",
        "tempo_data_no2_filtered = tempo_data_no2.where(filter_qa & filter_sza & filter_cf).squeeze()"
      ],
      "metadata": {
        "id": "PeOvtfj5bvO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get TEMPO Level-3 HCHO Data\n",
        "\n",
        "The below code is copied from previous examples of downloading TEMPO data. You will use it to download TEMPO Level-3 HCHO data for a region and time period of inerest.\n",
        "\n",
        "**Region of Interest**: Colorado Front Range (latitude 38 to 41, longitude -106 to -103)\n",
        "\n",
        "**Time of Interest**: July 27 to 30, 2024\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Modify the code in the next cells to download the TEMPO Level-3 HCHO data product for the region and time period of interest.\n",
        "\n",
        "* Run the cells in sequence to download the desired TEMPO data.\n",
        "\n",
        "<details>\n",
        "\n",
        "*Hint*: You will need to modify the `RoI`, `Collection id`, `start` and `stop` times.\n",
        "\n",
        "*Hint*: Use [Earthdata Search](https://search.earthdata.nasa.gov/search) to get the Collection id.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "Co0Nd8tHVG4Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Build the request*"
      ],
      "metadata": {
        "id": "URl_6VOWVYMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Structure the request:\n",
        "request_hcho = Request(\n",
        "    collection=Collection(id='TEMPO L3 HCHO Collection ID'),\n",
        "    temporal={\n",
        "        'start': dt.datetime(2001, 1, 1),\n",
        "        'stop': dt.datetime(2001, 1, 2)\n",
        "    },\n",
        "    spatial=BBox(RoI[0], RoI[1], RoI[2], RoI[3]),\n",
        ")\n",
        "\n",
        "# Check the request is valid:\n",
        "request_hcho.is_valid()"
      ],
      "metadata": {
        "id": "-wJbu0l4VcVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Submit and monitor the request*"
      ],
      "metadata": {
        "id": "XhK8Qbm0wFPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_id_hcho = harmony_client.submit(request_hcho)\n",
        "print(f\"jobID = {job_id_hcho}\")\n",
        "\n",
        "harmony_client.wait_for_processing(job_id_hcho, show_progress=True)"
      ],
      "metadata": {
        "id": "FZmy6XMDwRC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Download the results*"
      ],
      "metadata": {
        "id": "Qeqdc5gKwXyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_hcho = harmony_client.download_all(job_id_hcho, directory=download_dir)\n",
        "all_results_stored_hcho = [f.result() for f in results_hcho]\n",
        "\n",
        "print(f\"Number of files: {len(all_results_stored_hcho)}\")"
      ],
      "metadata": {
        "id": "7Bg50Wo7wcBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Open the files and combine into a single Dataset*"
      ],
      "metadata": {
        "id": "jaUfG4Cwwgjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define which variables to keep and rename:\n",
        "variables_to_keep_and_rename = {'product/vertical_column':'hcho_vertical_column',\n",
        "                                'product/main_data_quality_flag':'hcho_qc_flag',\n",
        "                                'geolocation/solar_zenith_angle':'hcho_sza',\n",
        "                                'support_data/eff_cloud_fraction':'hcho_cloud_fraction'\n",
        "                                }\n",
        "\n",
        "# Create a dictionary to store the data:\n",
        "data_dictionary = {variable:[] for variable in variables_to_keep_and_rename.keys()}\n",
        "\n",
        "# Loop through the result files:\n",
        "for result_file in sorted(all_results_stored_hcho):\n",
        "    # Loop throuch variables:\n",
        "    for variable in variables_to_keep_and_rename.keys():\n",
        "        # For each file and variable, add the data from that file to the appropriate list in the dictionary:\n",
        "        data_dictionary[variable] += [xr.open_datatree(result_file)[variable]]\n",
        "\n",
        "# Concatenate each list into a Dataset along the time dimenion:\n",
        "for variable in variables_to_keep_and_rename.keys():\n",
        "    data_dictionary[variable] = xr.concat(data_dictionary[variable],dim='time')\n",
        "\n",
        "# Merge the Datasets together:\n",
        "tempo_data_hcho = xr.merge([data_dictionary[variable] for variable in variables_to_keep_and_rename.keys()])\n",
        "\n",
        "# Rename the variables\n",
        "tempo_data_hcho = tempo_data_hcho.rename({variable.split('/')[1]:variables_to_keep_and_rename[variable] for variable in variables_to_keep_and_rename.keys()})\n",
        "\n",
        "# Examine the result:\n",
        "tempo_data_hcho"
      ],
      "metadata": {
        "id": "JtMPfc9nGqVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Apply quality control*\n",
        "\n",
        "<details>\n",
        "\n",
        "For this exercise, we will accept Suspect data, and also filter by Solar Zenith Angle (accepting values less than 80) and Cloud Fraction (accepting values less than 0.2)\n",
        "\n",
        "*Hint:* TEMPO quality flags are:\n",
        "\n",
        "* `0` = Normal quality (use for analysis)\n",
        "\n",
        "* `1` = Suspect quality (use with caution)\n",
        "\n",
        "* `2` = Bad quality (exclude from analysis)\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "BHK58Ob2HKGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filter_qa = tempo_data_hcho['hcho_qc_flag'] <= 1\n",
        "filter_sza = tempo_data_hcho['hcho_sza'] < 70\n",
        "filter_cf = tempo_data_hcho['hcho_cloud_fraction'] < 0.2\n",
        "\n",
        "tempo_data_hcho_filtered = tempo_data_hcho.where(filter_qa & filter_sza & filter_cf).squeeze()"
      ],
      "metadata": {
        "id": "Xz6J1AaQHOw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine into a single TEMPO Dataset\n",
        "\n",
        "To facilitate analysis, it will help if all the data are in one dataset.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Write code to merge the quality-controlled datasets together into one.\n",
        "\n",
        "* Write code to merge the original datasets (without quality control filters applied) into one.\n",
        "\n",
        "<details>\n",
        "\n",
        "*Hint*: To merge datasets together, use the following code example:\n",
        "\n",
        "```\n",
        "merged_dataset = xr.merge([dataset_1,dataset_2])\n",
        "```\n",
        "\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "QsHxt1shyuC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WRITE YOUR CODE HERE"
      ],
      "metadata": {
        "id": "8OQJ_BQVyx2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting NO2 and HCHO for different times and time intervals\n",
        "\n"
      ],
      "metadata": {
        "id": "QNyZ8RqneZef"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now create plots of NO2 and HCHO for the event, examining the effects of changing the averaging time and cloud fraction filtering."
      ],
      "metadata": {
        "id": "2lb5p5enfuXd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Instructuions*\n",
        "\n",
        "* Run the cell below to define the data projection and the mapping function."
      ],
      "metadata": {
        "id": "d2V9EuK-fmZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_proj = ccrs.PlateCarree()\n",
        "\n",
        "def make_nice_map(axis):\n",
        "    axis.add_feature(cfeature.STATES.with_scale('50m'), edgecolor=\"black\", linewidth=0.5)\n",
        "    axis.coastlines(resolution=\"50m\", color=\"black\", linewidth=1.0)\n",
        "\n",
        "    axis.set_extent([RoI[0], RoI[2], RoI[1], RoI[3]], crs=data_proj)\n",
        "    grid = axis.gridlines(draw_labels=[\"left\", \"bottom\"], dms=True)\n",
        "    grid.xformatter = LONGITUDE_FORMATTER\n",
        "    grid.yformatter = LATITUDE_FORMATTER"
      ],
      "metadata": {
        "id": "g5LcOd7MfkhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Datasets for a Single Timestamp\n",
        "\n",
        "The code below is taken from earlier plotting examples, with slight modifications. It is meant to plot the NO2 and HCHO data side-by-side, for a single time.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Identify where the code is getting its data inputs for NO2 and HCHO. Modify this to the filtered dataset you created earlier.\n",
        "\n",
        "* Run the cell and check the output.\n",
        "\n",
        "* Try picking different timestamps to plot and examining the output.\n",
        "\n",
        "<details>\n",
        "\n",
        "*Hint*: The code assumes the data are coming from a `tempo_data_filtered` Dataset.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "3PCmot6Xei6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a timestamp to plot:\n",
        "timestamp_local = pd.Timestamp('2024-07-29 14:30:00',tz='America/Denver')\n",
        "\n",
        "# Convert the timestamp from local time to UTC:\n",
        "timestamp_utc = timestamp_local.tz_convert(tz='UTC').to_datetime64()\n",
        "\n",
        "# Select the data to plot:\n",
        "data_to_plot_no2 = tempo_data_filtered['no2_vertical_column_troposphere'].sel(time=timestamp_utc,method='nearest')\n",
        "data_to_plot_hcho = tempo_data_filtered['hcho_vertical_column'].sel(time=timestamp_utc,method='nearest')\n",
        "\n",
        "# Plot the data on a map:\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 5), subplot_kw={\"projection\": data_proj})\n",
        "\n",
        "make_nice_map(ax[0])\n",
        "\n",
        "data_to_plot_no2.plot(\n",
        "    ax=ax[0], # axis to add plot to\n",
        "    cmap=plt.get_cmap('Purples'), # color scale\n",
        "    vmin=0, # minimum value\n",
        "    vmax=20e15, # maximum value\n",
        "    cbar_kwargs={'label':'Tropospheric Column $NO_2$ [$molecules/cm^2$]'} # set colorbar label\n",
        ")\n",
        "\n",
        "make_nice_map(ax[1])\n",
        "\n",
        "data_to_plot_hcho.plot(\n",
        "    ax=ax[1], # axis to add plot to\n",
        "    cmap=plt.get_cmap('Oranges'), # color scale\n",
        "    vmin=0, # minimum value\n",
        "    vmax=20e15, # maximum value\n",
        "    cbar_kwargs={'label':'Tropospheric Column $HCHO$ [$molecules/cm^2$]'} # set colorbar label\n",
        ")\n",
        "\n",
        "fig.suptitle(timestamp_local)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6YxpIKEgIOXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try Changing the Quality Control\n",
        "\n",
        "In the above plots, some of the densest parts of the plumes are missing. Aggressively filtering based on the cloud fraction can also remove thick smoke. To reduce this issue, we will apply a less strict quality control filter for the effective cloud fraction.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Revisit the combined dataset without filtering you created above.\n",
        "\n",
        "* Apply new quality control filters to that dataset to create a new filtered dataset. Specifically, we will accept Suspect data, filter by Solar Zenith Angle (accepting values less than 80), and Cloud Fraction (now accepting values less than 0.5, rahter than 0.2).\n",
        "\n",
        "<details>\n",
        "\n",
        "*Hint*: You can create a dataset which acts as a binary filtering mask by setting it equal to a logical expression, such as an inequality. For example:\n",
        "\n",
        "```\n",
        "binary_mask = data <= threshold\n",
        "```\n",
        "\n",
        "`binary_mask` will have value `True` wherever the values in `data` are less than or equal to `threshold`. You can use this to mask out data from the dataset. For example:\n",
        "\n",
        "```\n",
        "maksed_data = data.where(mask).squeeze()\n",
        "```\n",
        "\n",
        "`masked_data` will contain the values in `data` where the `mask` is `True`, and will be `NaN` otherwise.\n",
        "\n",
        "*Hint*: You can use the logical expression `&` to combine multiple binary masks. For example:\n",
        "\n",
        "```\n",
        "data_masked_by_a_and_b = data.where(mask_a & mask_b).squeeze()\n",
        "```\n",
        "\n",
        "*Hint*: Revisit the quality controls applied when the data were first downloaded for additional examples.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "mH3KxE2DeqcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WRITE YOUR CODE HERE"
      ],
      "metadata": {
        "id": "YN78Bz0SjhSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will re-plot the figures for a single timestamp.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Identify where the code is getting its data inputs for NO2 and HCHO. Modify this to the newly filtered dataset you just created.\n",
        "\n",
        "* Run the cell and check the output.\n",
        "\n",
        "* Try picking different timestamps to plot and examining the output.\n",
        "\n",
        "<details>\n",
        "\n",
        "*Hint*: The code assumes the data are coming from a `tempo_data_refiltered` Dataset.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "BJwMokPrjhv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a timestamp to plot:\n",
        "timestamp_local = pd.Timestamp('2024-07-29 14:30:00',tz='America/Denver')\n",
        "\n",
        "# Convert the timestamp from local time to UTC:\n",
        "timestamp_utc = timestamp_local.tz_convert(tz='UTC').to_datetime64()\n",
        "\n",
        "# Select the data to plot:\n",
        "data_to_plot_no2 = tempo_data_refiltered['no2_vertical_column_troposphere'].sel(time=timestamp_utc,method='nearest')\n",
        "data_to_plot_hcho = tempo_data_refiltered['hcho_vertical_column'].sel(time=timestamp_utc,method='nearest')\n",
        "\n",
        "# Plot the data on a map:\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 5), subplot_kw={\"projection\": data_proj})\n",
        "\n",
        "make_nice_map(ax[0])\n",
        "\n",
        "data_to_plot_no2.plot(\n",
        "    ax=ax[0], # axis to add plot to\n",
        "    cmap=plt.get_cmap('Purples'), # color scale\n",
        "    vmin=0, # minimum value\n",
        "    vmax=20e15, # maximum value\n",
        "    cbar_kwargs={'label':'Tropospheric Column $NO_2$ [$molecules/cm^2$]'} # set colorbar label\n",
        ")\n",
        "\n",
        "make_nice_map(ax[1])\n",
        "\n",
        "data_to_plot_hcho.plot(\n",
        "    ax=ax[1], # axis to add plot to\n",
        "    cmap=plt.get_cmap('Oranges'), # color scale\n",
        "    vmin=0, # minimum value\n",
        "    vmax=20e15, # maximum value\n",
        "    cbar_kwargs={'label':'Tropospheric Column $HCHO$ [$molecules/cm^2$]'} # set colorbar label\n",
        ")\n",
        "\n",
        "fig.suptitle(timestamp_local)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3RZdOr1mjiLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Datasets Averaged for Multiple Timestamps\n",
        "\n",
        "Plots at single timesteps can be noisy, and have missing data. To reduce some of these data gaps and smooth out noise, we can average across multiple timesteps.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Write code to define the `data_to_plot_no2` and `data_to_plot_hcho` variables.\n",
        "\n",
        "  * `data_to_plot_no2` should be the average of your newly filtered NO2 tropospheric column data between `timestamp_utc_start` and `timestamp_utc_stop`\n",
        "\n",
        "  * `data_to_plot_hcho` should be the average of your newly filtered HCHO column data between `timestamp_utc_start` and `timestamp_utc_stop`\n",
        "\n",
        "* Run the cell and check the output.\n",
        "\n",
        "* Try picking different starting and ending times for the averaging period and examining the output.\n",
        "\n",
        "<details>\n",
        "\n",
        "*Hint*: This example code will average the values of `data` between `start_time` and `stop_time`:\n",
        "\n",
        "```\n",
        "time_average_data = data.sel(time=slice(start_time,stop_time)).mean('time')\n",
        "```\n",
        "\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "JXQwEiy2emPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a timestamp to plot:\n",
        "timestamp_local_start = pd.Timestamp('2024-07-29 00:00:00',tz='America/Denver')\n",
        "timestamp_local_stop = pd.Timestamp('2024-07-30 23:59:59',tz='America/Denver')\n",
        "\n",
        "# Convert the timestamp from local time to UTC:\n",
        "timestamp_utc_start = timestamp_local_start.tz_convert(tz='UTC').to_datetime64()\n",
        "timestamp_utc_stop = timestamp_local_stop.tz_convert(tz='UTC').to_datetime64()\n",
        "\n",
        "# Select the data to plot:\n",
        "data_to_plot_no2 = # WRITE YOUR CODE HERE\n",
        "data_to_plot_hcho = # WRITE YOUR CODE HERE\n",
        "\n",
        "# Plot the data on a map:\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 5), subplot_kw={\"projection\": data_proj})\n",
        "\n",
        "make_nice_map(ax[0])\n",
        "\n",
        "data_to_plot_no2.plot(\n",
        "    ax=ax[0], # axis to add plot to\n",
        "    cmap=plt.get_cmap('Purples'), # color scale\n",
        "    vmin=0, # minimum value\n",
        "    vmax=20e15, # maximum value\n",
        "    cbar_kwargs={'label':'Tropospheric Column $NO_2$ [$molecules/cm^2$]'} # set colorbar label\n",
        ")\n",
        "\n",
        "make_nice_map(ax[1])\n",
        "\n",
        "data_to_plot_hcho.plot(\n",
        "    ax=ax[1], # axis to add plot to\n",
        "    cmap=plt.get_cmap('Oranges'), # color scale\n",
        "    vmin=0, # minimum value\n",
        "    vmax=20e15, # maximum value\n",
        "    cbar_kwargs={'label':'Tropospheric Column $HCHO$ [$molecules/cm^2$]'} # set colorbar label\n",
        ")\n",
        "\n",
        "fig.suptitle(f'{timestamp_local_start} to {timestamp_local_stop}')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WgKqAbt7imUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Daily-Average Plots\n",
        "\n",
        "Plots averaged over about a day are relatively smooth and complete. We will plot a series of daily-averaged maps of NO2 and HCHO.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* The code below has been set up to plot daily averages for a sequence of days, defined by `days_to_plot`. Check that `days_to_plot` starts on the correct day and has the correct number of days (`periods`) for the time interval of your dataset.\n",
        "\n",
        "* Copy the code you created above to define the `data_to_plot_no2` and `data_to_plot_hcho` variables.\n",
        "\n",
        "* Run the cell and check the outputs."
      ],
      "metadata": {
        "id": "3FF1ctR9hyNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a sequence of days to plot:\n",
        "days_to_plot = pd.date_range(\"2024-07-27\", periods=3, freq=\"D\", tz='America/Denver')\n",
        "\n",
        "# Create the figure\n",
        "fig, ax = plt.subplots(nrows=len(days_to_plot), ncols=2, figsize=(10, 5*len(days_to_plot)), subplot_kw={\"projection\": data_proj})\n",
        "\n",
        "for day_index,day_timestamp in enumerate(days_to_plot):\n",
        "    # Choose a timestamp to plot:\n",
        "    timestamp_local_start = day_timestamp\n",
        "    timestamp_local_stop = day_timestamp + pd.Timedelta(days=1)\n",
        "\n",
        "    # Convert the timestamp from local time to UTC:\n",
        "    timestamp_utc_start = timestamp_local_start.tz_convert(tz='UTC').to_datetime64()\n",
        "    timestamp_utc_stop = timestamp_local_stop.tz_convert(tz='UTC').to_datetime64()\n",
        "\n",
        "    # Select the data to plot:\n",
        "    data_to_plot_no2 = # WRITE YOUR CODE HERE\n",
        "    data_to_plot_hcho = # WRITE YOUR CODE HERE\n",
        "\n",
        "    # Plot the data on a map:\n",
        "    make_nice_map(ax[day_index,0])\n",
        "\n",
        "    data_to_plot_no2.plot(\n",
        "        ax=ax[day_index,0], # axis to add plot to\n",
        "        cmap=plt.get_cmap('Purples'), # color scale\n",
        "        vmin=0, # minimum value\n",
        "        vmax=20e15, # maximum value\n",
        "        cbar_kwargs={'label':'Tropospheric Column $NO_2$ [$molecules/cm^2$]'} # set colorbar label\n",
        "    )\n",
        "\n",
        "    ax[day_index,0].set_title(timestamp_local_start.date())\n",
        "\n",
        "    make_nice_map(ax[day_index,1])\n",
        "\n",
        "    data_to_plot_hcho.plot(\n",
        "        ax=ax[day_index,1], # axis to add plot to\n",
        "        cmap=plt.get_cmap('Oranges'), # color scale\n",
        "        vmin=0, # minimum value\n",
        "        vmax=20e15, # maximum value\n",
        "        cbar_kwargs={'label':'Tropospheric Column $HCHO$ [$molecules/cm^2$]'} # set colorbar label\n",
        "    )\n",
        "\n",
        "    ax[day_index,1].set_title(timestamp_local_start.date())\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8E3JYStBoTdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyse the Formaldehyde-to-NO2 Ratios\n",
        "\n",
        "Finally, will can assess the Formaldehyde-to-NO2 ratios as a potential indicator of the causes of ozone formation. The code below is similar to the above, and is intended to plot daily averages of a variable `data_to_plot_fnr`, which you need to define.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Copy the code you created above to define the `data_to_plot_no2` and `data_to_plot_hcho` variables.\n",
        "\n",
        "* Add code to define `data_to_plot_fnr` as the ratio of `data_to_plot_hcho` and `data_to_plot_no2`.\n",
        "\n",
        "* Run the cell and check the outputs.\n",
        "\n",
        "<details>\n",
        "\n",
        "*Hint*: The formula for a ratio in python is: `ratio = numerator/denominator`"
      ],
      "metadata": {
        "id": "FapQN81P1Hzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a sequence of days to plot:\n",
        "days_to_plot = pd.date_range(\"2024-07-27\", periods=3, freq=\"D\", tz='America/Denver')\n",
        "\n",
        "# Create the figure\n",
        "fig, ax = plt.subplots(nrows=len(days_to_plot), ncols=1, figsize=(7, 5*len(days_to_plot)), subplot_kw={\"projection\": data_proj})\n",
        "\n",
        "for day_index,day_timestamp in enumerate(days_to_plot):\n",
        "    # Choose a timestamp to plot:\n",
        "    timestamp_local_start = day_timestamp\n",
        "    timestamp_local_stop = day_timestamp + pd.Timedelta(days=1)\n",
        "\n",
        "    # Convert the timestamp from local time to UTC:\n",
        "    timestamp_utc_start = timestamp_local_start.tz_convert(tz='UTC').to_datetime64()\n",
        "    timestamp_utc_stop = timestamp_local_stop.tz_convert(tz='UTC').to_datetime64()\n",
        "\n",
        "    # Select the data to plot:\n",
        "    data_to_plot_no2 = # WRITE YOUR CODE HERE\n",
        "    data_to_plot_hcho = # WRITE YOUR CODE HERE\n",
        "    data_to_plot_fnr = # WRITE YOUR CODE HERE\n",
        "\n",
        "    # Plot the data on a map:\n",
        "    make_nice_map(ax[day_index])\n",
        "\n",
        "    data_to_plot_fnr.plot(\n",
        "        ax=ax[day_index], # axis to add plot to\n",
        "        cmap=plt.get_cmap('PuOr_r'), # color scale\n",
        "        vmin=1, # minimum value\n",
        "        vmax=11, # maximum value\n",
        "        cbar_kwargs={'label':'$HCHO$ / $NO_2$'} # set colorbar label\n",
        "    )\n",
        "\n",
        "    ax[day_index].set_title(timestamp_local_start.date())\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wA9lbMnMqvHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bonus: Compare with AirNow Ozone Monitor Data\n",
        "\n",
        "We can add the surface ozone monitor data into our plots for additional context."
      ],
      "metadata": {
        "id": "e5GEKvu3cdrh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use pyrsig to download AirNow ozone\n",
        "\n",
        "We will use the [pyrsig package](https://barronh.github.io/pyrsig/) to easily bring the AirNow ozone data into python. Below is a template for how a query is structured and submitted to pyrsig. The result will be a data table with the ozone data, timestamps, and station information.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Modify the template to have the approrpiate start end and dates.\n",
        "\n",
        "* Modify the template to have the appropriate bounding box for the region of interest.\n",
        "\n",
        "* Run the cell to examine the output table."
      ],
      "metadata": {
        "id": "7c7NvIAEcgQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the query for pyrisg:\n",
        "api = pyrsig.RsigApi(bdate=\"2024-07-27\", # start date of the query, in the format \"YYYY-MM-DD\"\n",
        "                     edate=\"2024-07-30\", # end date of the query, in the format \"YYY-MM-DD\"\n",
        "                     bbox=(RoI[0],RoI[1],RoI[2],RoI[3]), # bounding box for the query, in the format (minimum_longitude,minimum_latitude,maximum_longitude,maximum_latitude)\n",
        "                     workdir=download_dir, # temporary directory to store the downloaded data\n",
        "                     gridfit=True) # data are not being re-aligned to a grid\n",
        "airnowkey = \"airnow.ozone\" # this is the pyrsig code to specify ozone data from AirNow\n",
        "\n",
        "# Execute the query to download the data:\n",
        "airnow_data = api.to_dataframe(airnowkey, unit_keys=False, parse_dates=True)\n",
        "\n",
        "# Examine the resulting table:\n",
        "airnow_data"
      ],
      "metadata": {
        "id": "V73G4YMDdNs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Map Comparison Plot\n",
        "\n",
        "Finally, we will overlay ozone monitor averages onto an Formaldehyde-to-NO2 ratio map. The code example below should generate this plot, but again, it assumes the data are in specifically named datasets which might not exist in your run of the code.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Examine the code and see if you can understand what is happening in each part.\n",
        "\n",
        "* Try to run the code below, troubleshooting any errors you encounter.\n",
        "\n",
        "* Try changing the axis limits on the ozone plot colorbar.\n",
        "\n",
        "<details>\n",
        "\n",
        "*Hint*: If youn are getting errors, try copying subsets of the code into a new cell to run it incrementally, and see where the errors are coming from. Put the name of a variable in a cell by itself and run that cell to see what the variable looks like."
      ],
      "metadata": {
        "id": "wCsWa5KzcrbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a sequence of days to plot:\n",
        "days_to_plot = pd.date_range(\"2024-07-27\", periods=3, freq=\"D\", tz='America/Denver')\n",
        "\n",
        "# Create the figure\n",
        "fig, ax = plt.subplots(nrows=len(days_to_plot), ncols=1, figsize=(10, 5*len(days_to_plot)), subplot_kw={\"projection\": data_proj})\n",
        "\n",
        "for day_index,day_timestamp in enumerate(days_to_plot):\n",
        "    # Choose a timestamp to plot:\n",
        "    timestamp_local_start = day_timestamp\n",
        "    timestamp_local_stop = day_timestamp + pd.Timedelta(days=1)\n",
        "\n",
        "    # Convert the timestamp from local time to UTC:\n",
        "    timestamp_utc_start = timestamp_local_start.tz_convert(tz='UTC').to_datetime64()\n",
        "    timestamp_utc_stop = timestamp_local_stop.tz_convert(tz='UTC').to_datetime64()\n",
        "\n",
        "    # Select the data to plot:\n",
        "    data_to_plot_no2 = tempo_data_refiltered['no2_vertical_column_troposphere'].sel(time=slice(timestamp_utc_start,timestamp_utc_stop)).mean('time')\n",
        "    data_to_plot_hcho = tempo_data_refiltered['hcho_vertical_column'].sel(time=slice(timestamp_utc_start,timestamp_utc_stop)).mean('time')\n",
        "    data_to_plot_fnr = data_to_plot_hcho/data_to_plot_no2\n",
        "\n",
        "    # Subset the AirNow ozone data to plot:\n",
        "    airnow_data_subset = airnow_data.where((airnow_data['time'] >= pd.Timestamp(timestamp_utc_start,tz='UTC')) & (airnow_data['time'] < pd.Timestamp(timestamp_utc_stop,tz='UTC'))).dropna(how='all')\n",
        "\n",
        "    # Compute the average:\n",
        "    average_ozone_to_plot = airnow_data_subset[['STATION','LATITUDE','LONGITUDE','ozone']].groupby('STATION').mean()\n",
        "\n",
        "    # Plot the data on a map:\n",
        "    make_nice_map(ax[day_index])\n",
        "\n",
        "    ratio_plot = data_to_plot_fnr.plot(\n",
        "        ax=ax[day_index], # axis to add plot to\n",
        "        cmap=plt.get_cmap('PuOr_r'), # color scale\n",
        "        vmin=1, # minimum value\n",
        "        vmax=11, # maximum value\n",
        "        add_colorbar=False\n",
        "    )\n",
        "\n",
        "    colorbar_ratio = plt.colorbar(ratio_plot)\n",
        "    colorbar_ratio.set_label('HCHO / $NO_2$')\n",
        "\n",
        "    ozone_plot = ax[day_index].scatter(average_ozone_to_plot['LONGITUDE'],\n",
        "                            average_ozone_to_plot['LATITUDE'],\n",
        "                            s=100,\n",
        "                            c=average_ozone_to_plot['ozone'],\n",
        "                            cmap=plt.get_cmap('Greens'),\n",
        "                            vmin=40,\n",
        "                            vmax=80,\n",
        "                            edgecolors='black')\n",
        "\n",
        "    colorbar_ozone = plt.colorbar(ozone_plot)\n",
        "    colorbar_ozone.set_label('Ozone [ppb]')\n",
        "\n",
        "    ax[day_index].set_title(timestamp_local_start.date())\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5Rwc1Wh4BREW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}