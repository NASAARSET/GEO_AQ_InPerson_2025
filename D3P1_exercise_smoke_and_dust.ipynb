{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "\n",
        "This exercise demonstrates how TEMPO data can be used to track smoke and dust and perform quantitative analysis.\n",
        "\n",
        "**Notebook Author / Affiliation**\n",
        "\n",
        "* Author: Carl Malings / NASA ARSET\n",
        "* This notebook is based on examples from the [ASDC Data and User Services Github](https://github.com/nasa/ASDC_Data_and_User_Services)."
      ],
      "metadata": {
        "id": "ie_Ber64pkVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Package Installation and Setup\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Run the cell below to install the non-standard packages required for this exercise."
      ],
      "metadata": {
        "id": "1irxs4Va0IQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet harmony-py cartopy"
      ],
      "metadata": {
        "id": "OdBaZPXd0H_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Instructions*\n",
        "\n",
        "* Run the code cell below to import the required packages."
      ],
      "metadata": {
        "id": "z1205WzR3K9w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78NELfmHz4gW"
      },
      "outputs": [],
      "source": [
        "# Downloading TEMPO data\n",
        "import datetime as dt\n",
        "import getpass\n",
        "import os\n",
        "from harmony import BBox, Client, Collection, Request\n",
        "from harmony.config import Environment\n",
        "\n",
        "# Opening TEMPO data files\n",
        "import xarray as xr\n",
        "\n",
        "# Creating graphics\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "import matplotlib.pyplot as plt\n",
        "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
        "from xarray.plot.utils import label_from_attrs\n",
        "\n",
        "# Working with data tables\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download TEMPO Data\n",
        "\n",
        "The first part of this exercise will be to download the TEMPO NO2, HCHO and Aerosol Index data for the region and time period of interest.\n",
        "\n",
        "**Region of Interest**: South-Central US (latitude 30 to 40, longitude -102 to -92)\n",
        "\n",
        "**Time of Interest**: March 14, 2025 (03/14/2025 13:00 UTC to 03/15/2025 00:00 UTC)\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Run the cell below and enter your Earthdata credentials to prepare for data downloading"
      ],
      "metadata": {
        "id": "IY9pYsFLqGN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "username = input(\"Username:\")\n",
        "\n",
        "harmony_client = Client(env=Environment.PROD, auth=(username, getpass.getpass()))"
      ],
      "metadata": {
        "id": "G3yW37_nS2gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get TEMPO Level-3 NO2 Data"
      ],
      "metadata": {
        "id": "pBXn2JTq0Isv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code is copied from previous examples of downloading TEMPO data. You will use it to download TEMPO Level-3 NO2 data for a region and time period of inerest.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Modify the code in the next cells to download the TEMPO Level-3 NO2 data product for the region and time period of interest.\n",
        "\n",
        "* Run the cells in sequence to download the desired TEMPO data.\n",
        "\n",
        "<details>\n",
        "\n",
        "*Hint*: You will need to modify the `RoI`, `Collection id`, `start` and `stop` times.\n",
        "\n",
        "*Hint*: Use [Earthdata Search](https://search.earthdata.nasa.gov/search) to get the Collection id.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "ckBxhj20WqAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Build the request*"
      ],
      "metadata": {
        "id": "6utEczoTSJo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This list will save the bounding box limits for later use:\n",
        "RoI = [-180, -90, 180, 90]\n",
        "\n",
        "# Structure the request:\n",
        "request_no2 = Request(\n",
        "    collection=Collection(id='TEMPO L3 NO2 Collection ID'),\n",
        "    temporal={\n",
        "        'start': dt.datetime(2001, 1, 1, 0),\n",
        "        'stop': dt.datetime(2001, 1, 1, 23)\n",
        "    },\n",
        "    spatial=BBox(RoI[0], RoI[1], RoI[2], RoI[3]),\n",
        ")\n",
        "\n",
        "# Check the request is valid:\n",
        "request_no2.is_valid()"
      ],
      "metadata": {
        "id": "HvvCgc3L2qOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Submit and monitor the request*"
      ],
      "metadata": {
        "id": "xxKk-W2XSFE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_id_no2 = harmony_client.submit(request_no2)\n",
        "print(f\"jobID = {job_id_no2}\")\n",
        "\n",
        "harmony_client.wait_for_processing(job_id_no2, show_progress=True)"
      ],
      "metadata": {
        "id": "bd5sdK4B3sq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Download the results*"
      ],
      "metadata": {
        "id": "RwiabuNlSC-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "download_dir = os.path.expanduser(\"~/tempo_data_smoke_and_dust_exercise\")\n",
        "os.makedirs(download_dir, exist_ok=True)\n",
        "\n",
        "results_no2 = harmony_client.download_all(job_id_no2, directory=download_dir)\n",
        "all_results_stored_no2 = [f.result() for f in results_no2]\n",
        "\n",
        "print(f\"Number of files: {len(all_results_stored_no2)}\")"
      ],
      "metadata": {
        "id": "O_9NQeeA31QL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Open the files and combine into a single Dataset*\n",
        "\n",
        "<details>\n",
        "\n",
        "Note that there is a slightly different structure to this code than seen in previous examples. The dictionary `variables_to_keep_and_rename` provides a complete list of the variables to keep and the new names they will be assigned. This makes it more straightforward to change what variables are kept, so that the same code can be re-used more easily for the other TEMPO products.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "T3sxCjy0R9UG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define which variables to keep and rename:\n",
        "variables_to_keep_and_rename = {'product/vertical_column_troposphere':'no2_vertical_column_troposphere',\n",
        "                                'product/main_data_quality_flag':'no2_qc_flag',\n",
        "                                'geolocation/solar_zenith_angle':'no2_sza',\n",
        "                                'support_data/eff_cloud_fraction':'no2_cloud_fraction'\n",
        "                                }\n",
        "\n",
        "# Create a dictionary to store the data:\n",
        "data_dictionary = {variable:[] for variable in variables_to_keep_and_rename.keys()}\n",
        "\n",
        "# Loop through the result files:\n",
        "for result_file in sorted(all_results_stored_no2):\n",
        "    # Loop throuch variables:\n",
        "    for variable in variables_to_keep_and_rename.keys():\n",
        "        # For each file and variable, add the data from that file to the appropriate list in the dictionary:\n",
        "        data_dictionary[variable] += [xr.open_datatree(result_file)[variable]]\n",
        "\n",
        "# Concatenate each list into a Dataset along the time dimenion:\n",
        "for variable in variables_to_keep_and_rename.keys():\n",
        "    data_dictionary[variable] = xr.concat(data_dictionary[variable],dim='time')\n",
        "\n",
        "# Merge the Datasets together:\n",
        "tempo_data_no2 = xr.merge([data_dictionary[variable] for variable in variables_to_keep_and_rename.keys()])\n",
        "\n",
        "# Rename the variables\n",
        "tempo_data_no2 = tempo_data_no2.rename({variable.split('/')[1]:variables_to_keep_and_rename[variable] for variable in variables_to_keep_and_rename.keys()})\n",
        "\n",
        "# Examine the result:\n",
        "tempo_data_no2"
      ],
      "metadata": {
        "id": "EpAOxM814iFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Apply quality control*\n",
        "\n",
        "<details>\n",
        "\n",
        "For this exercise, we will accept Suspect data, and also filter by Solar Zenith Angle (accepting values less than 70) and Cloud Fraction (accepting values less than 0.2)\n",
        "\n",
        "*Hint:* TEMPO quality flags are:\n",
        "\n",
        "* `0` = Normal quality (use for analysis)\n",
        "\n",
        "* `1` = Suspect quality (use with caution)\n",
        "\n",
        "* `2` = Bad quality (exclude from analysis)\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "eLLRlJQlzwyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filter_qa = tempo_data_no2['no2_qc_flag'] <= 1\n",
        "filter_sza = tempo_data_no2['no2_sza'] < 70\n",
        "filter_cf = tempo_data_no2['no2_cloud_fraction'] < 0.2\n",
        "\n",
        "tempo_data_no2_filtered = tempo_data_no2.where(filter_qa & filter_sza & filter_cf).squeeze()"
      ],
      "metadata": {
        "id": "LobZBeIFzxK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Plot Maps of Tropospheric Column NO2*\n",
        "\n",
        "The code below is taken from earlier plotting examples, with slight modifications.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Run the cell and check the output.\n",
        "\n",
        "* Try picking different timestamps to plot and examining the output."
      ],
      "metadata": {
        "id": "O_Jh7DwTB6Dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_proj = ccrs.PlateCarree()\n",
        "\n",
        "def make_nice_map(axis):\n",
        "    axis.add_feature(cfeature.STATES.with_scale('50m'), edgecolor=\"black\", linewidth=0.5)\n",
        "    axis.coastlines(resolution=\"50m\", color=\"black\", linewidth=1.0)\n",
        "\n",
        "    axis.set_extent([RoI[0], RoI[2], RoI[1], RoI[3]], crs=data_proj)\n",
        "    grid = axis.gridlines(draw_labels=[\"left\", \"bottom\"], dms=True)\n",
        "    grid.xformatter = LONGITUDE_FORMATTER\n",
        "    grid.yformatter = LATITUDE_FORMATTER\n",
        "\n",
        "# Choose a timestamp to plot:\n",
        "timestamp_local = pd.Timestamp('2025-03-14 14:30:00',tz='America/Chicago')\n",
        "\n",
        "# Convert the timestamp from local time to UTC:\n",
        "timestamp_utc = timestamp_local.tz_convert(tz='UTC').to_datetime64()\n",
        "\n",
        "# Select the data to plot:\n",
        "data_to_plot = tempo_data_no2_filtered['no2_vertical_column_troposphere'].sel(time=timestamp_utc,method='nearest')\n",
        "\n",
        "# Plot the data on a map:\n",
        "fig, ax = plt.subplots(figsize=(10, 6), subplot_kw={\"projection\": data_proj})\n",
        "\n",
        "make_nice_map(ax)\n",
        "\n",
        "data_to_plot.plot(\n",
        "    ax=ax, # axis to add plot to\n",
        "    cmap=plt.get_cmap('Oranges'), # color scale\n",
        "    vmin=0, # minimum value\n",
        "    vmax=5e15, # maximum value\n",
        "    cbar_kwargs={'label':'Tropospheric Column $NO_2$ [$molecules/cm^2$]'} # set colorbar label\n",
        ")\n",
        "\n",
        "ax.set_title(timestamp_local)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HQ8XyZDmB6fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get TEMPO Level-3 HCHO Data"
      ],
      "metadata": {
        "id": "nkL0brMWFjWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, download TEMPO Level-3 HCHO data for a region and time period of inerest.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Modify the code in the next cells to download the TEMPO Level-3 HCHO data product for the region and time period of interest.\n",
        "\n",
        "* Run the cells in sequence to download the desired TEMPO data.\n",
        "\n",
        "<details>\n",
        "\n",
        "*Hint*: You will need to modify the `Collection id`, `start` and `stop` times.\n",
        "\n",
        "*Hint*: Use [Earthdata Search](https://search.earthdata.nasa.gov/search) to get the Collection id.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "RtAlbCWrFtLS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Build the request*"
      ],
      "metadata": {
        "id": "URl_6VOWVYMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Structure the request:\n",
        "request_hcho = Request(\n",
        "    collection=Collection(id='TEMPO L3 HCHO Collection ID'),\n",
        "    temporal={\n",
        "        'start': dt.datetime(2001, 1, 1, 0),\n",
        "        'stop': dt.datetime(2001, 1, 1, 23)\n",
        "    },\n",
        "    spatial=BBox(RoI[0], RoI[1], RoI[2], RoI[3]),\n",
        ")\n",
        "\n",
        "# Check the request is valid:\n",
        "request_hcho.is_valid()"
      ],
      "metadata": {
        "id": "wUawIX4fGCj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Submit and monitor the request*"
      ],
      "metadata": {
        "id": "XhK8Qbm0wFPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_id_hcho = harmony_client.submit(request_hcho)\n",
        "print(f\"jobID = {job_id_hcho}\")\n",
        "\n",
        "harmony_client.wait_for_processing(job_id_hcho, show_progress=True)"
      ],
      "metadata": {
        "id": "FZmy6XMDwRC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Download the results*"
      ],
      "metadata": {
        "id": "Qeqdc5gKwXyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_hcho = harmony_client.download_all(job_id_hcho, directory=download_dir)\n",
        "all_results_stored_hcho = [f.result() for f in results_hcho]\n",
        "\n",
        "print(f\"Number of files: {len(all_results_stored_hcho)}\")"
      ],
      "metadata": {
        "id": "7Bg50Wo7wcBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Open the files and combine into a single Dataset*"
      ],
      "metadata": {
        "id": "jaUfG4Cwwgjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define which variables to keep and rename:\n",
        "variables_to_keep_and_rename = {'product/vertical_column':'hcho_vertical_column',\n",
        "                                'product/main_data_quality_flag':'hcho_qc_flag',\n",
        "                                'geolocation/solar_zenith_angle':'hcho_sza',\n",
        "                                'support_data/eff_cloud_fraction':'hcho_cloud_fraction'\n",
        "                                }\n",
        "\n",
        "# Create a dictionary to store the data:\n",
        "data_dictionary = {variable:[] for variable in variables_to_keep_and_rename.keys()}\n",
        "\n",
        "# Loop through the result files:\n",
        "for result_file in sorted(all_results_stored_hcho):\n",
        "    # Loop throuch variables:\n",
        "    for variable in variables_to_keep_and_rename.keys():\n",
        "        # For each file and variable, add the data from that file to the appropriate list in the dictionary:\n",
        "        data_dictionary[variable] += [xr.open_datatree(result_file)[variable]]\n",
        "\n",
        "# Concatenate each list into a Dataset along the time dimenion:\n",
        "for variable in variables_to_keep_and_rename.keys():\n",
        "    data_dictionary[variable] = xr.concat(data_dictionary[variable],dim='time')\n",
        "\n",
        "# Merge the Datasets together:\n",
        "tempo_data_hcho = xr.merge([data_dictionary[variable] for variable in variables_to_keep_and_rename.keys()])\n",
        "\n",
        "# Rename the variables\n",
        "tempo_data_hcho = tempo_data_hcho.rename({variable.split('/')[1]:variables_to_keep_and_rename[variable] for variable in variables_to_keep_and_rename.keys()})\n",
        "\n",
        "# Examine the result:\n",
        "tempo_data_hcho"
      ],
      "metadata": {
        "id": "JtMPfc9nGqVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Apply quality control*\n",
        "\n",
        "<details>\n",
        "\n",
        "For this exercise, we will accept Suspect data, and also filter by Solar Zenith Angle (accepting values less than 70) and Cloud Fraction (accepting values less than 0.2)\n",
        "\n",
        "*Hint:* TEMPO quality flags are:\n",
        "\n",
        "* `0` = Normal quality (use for analysis)\n",
        "\n",
        "* `1` = Suspect quality (use with caution)\n",
        "\n",
        "* `2` = Bad quality (exclude from analysis)\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "BHK58Ob2HKGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filter_qa = tempo_data_hcho['hcho_qc_flag'] <= 1\n",
        "filter_sza = tempo_data_hcho['hcho_sza'] < 70\n",
        "filter_cf = tempo_data_hcho['hcho_cloud_fraction'] < 0.2\n",
        "\n",
        "tempo_data_hcho_filtered = tempo_data_hcho.where(filter_qa & filter_sza & filter_cf).squeeze()"
      ],
      "metadata": {
        "id": "Xz6J1AaQHOw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Plot Maps of Column HCHO*\n",
        "\n",
        "The code below is taken from earlier plotting examples, with slight modifications.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Run the cell and check the output.\n",
        "\n",
        "* Try picking different timestamps to plot and examining the output."
      ],
      "metadata": {
        "id": "u30MQz0vHZ0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a timestamp to plot:\n",
        "timestamp_local = pd.Timestamp('2025-03-14 14:30:00',tz='America/Chicago')\n",
        "\n",
        "# Convert the timestamp from local time to UTC:\n",
        "timestamp_utc = timestamp_local.tz_convert(tz='UTC').to_datetime64()\n",
        "\n",
        "# Select the data to plot:\n",
        "data_to_plot = tempo_data_hcho_filtered['hcho_vertical_column'].sel(time=timestamp_utc,method='nearest')\n",
        "\n",
        "# Plot the data on a map:\n",
        "fig, ax = plt.subplots(figsize=(10, 6), subplot_kw={\"projection\": data_proj})\n",
        "\n",
        "make_nice_map(ax)\n",
        "\n",
        "data_to_plot.plot(\n",
        "    ax=ax, # axis to add plot to\n",
        "    cmap=plt.get_cmap('Purples'), # color scale\n",
        "    vmin=0, # minimum value\n",
        "    vmax=20e15, # maximum value\n",
        "    cbar_kwargs={'label':'Tropospheric Column $HCHO$ [$molecules/cm^2$]'} # set colorbar label\n",
        ")\n",
        "\n",
        "ax.set_title(timestamp_local)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6YxpIKEgIOXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get TEMPO Level-3 Ozone Data"
      ],
      "metadata": {
        "id": "NcHf23GvIrBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, download TEMPO Level-3 Ozone Total Column data for a region and time period of inerest. We need this because these files also contain the UV Aerosol Index data.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Modify the code in the next cells to download the TEMPO Level-3 Ozone Total Column data product for the region and time period of interest.\n",
        "\n",
        "* Run the cells in sequence to download the desired TEMPO data.\n",
        "\n",
        "<details>\n",
        "\n",
        "*Hint*: You will need to modify the `Collection id`, `start` and `stop` times.\n",
        "\n",
        "*Hint*: Use [Earthdata Search](https://search.earthdata.nasa.gov/search) to get the Collection id.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "dGN81HqAIwNf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Build the request*"
      ],
      "metadata": {
        "id": "4DaDsGXVI9Rb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Structure the request:\n",
        "request_o3tot = Request(\n",
        "    collection=Collection(id='TEMPO L3 O3TOT Collection ID'),\n",
        "    temporal={\n",
        "        'start': dt.datetime(2001, 1, 1, 0),\n",
        "        'stop': dt.datetime(2001, 1, 1, 23)\n",
        "    },\n",
        "    spatial=BBox(RoI[0], RoI[1], RoI[2], RoI[3]),\n",
        ")\n",
        "\n",
        "# Check the request is valid:\n",
        "request_o3tot.is_valid()"
      ],
      "metadata": {
        "id": "kyW6q9_7I_d4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Submit and monitor the request*"
      ],
      "metadata": {
        "id": "9GOLqh41JkK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_id_o3tot = harmony_client.submit(request_o3tot)\n",
        "print(f\"jobID = {job_id_o3tot}\")\n",
        "\n",
        "harmony_client.wait_for_processing(job_id_o3tot, show_progress=True)"
      ],
      "metadata": {
        "id": "P2CBO-HpJozJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Download the results*"
      ],
      "metadata": {
        "id": "7TnQk8kMJv-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_o3tot = harmony_client.download_all(job_id_o3tot, directory=download_dir)\n",
        "all_results_stored_o3tot = [f.result() for f in results_o3tot]\n",
        "\n",
        "print(f\"Number of files: {len(all_results_stored_o3tot)}\")"
      ],
      "metadata": {
        "id": "gLBQ7BG9J_z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Open the files and combine into a single Dataset*"
      ],
      "metadata": {
        "id": "9Of7yAy6Jy8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define which variables to keep and rename:\n",
        "variables_to_keep_and_rename = {'product/uv_aerosol_index':'uv_aerosol_index',\n",
        "                                'geolocation/solar_zenith_angle':'o3_sza',\n",
        "                                }\n",
        "\n",
        "# Create a dictionary to store the data:\n",
        "data_dictionary = {variable:[] for variable in variables_to_keep_and_rename.keys()}\n",
        "\n",
        "# Loop through the result files:\n",
        "for result_file in sorted(all_results_stored_o3tot):\n",
        "    # Loop throuch variables:\n",
        "    for variable in variables_to_keep_and_rename.keys():\n",
        "        # For each file and variable, add the data from that file to the appropriate list in the dictionary:\n",
        "        data_dictionary[variable] += [xr.open_datatree(result_file)[variable]]\n",
        "\n",
        "# Concatenate each list into a Dataset along the time dimenion:\n",
        "for variable in variables_to_keep_and_rename.keys():\n",
        "    data_dictionary[variable] = xr.concat(data_dictionary[variable],dim='time')\n",
        "\n",
        "# Merge the Datasets together:\n",
        "tempo_data_uvai = xr.merge([data_dictionary[variable] for variable in variables_to_keep_and_rename.keys()])\n",
        "\n",
        "# Rename the variables\n",
        "tempo_data_uvai = tempo_data_uvai.rename({variable.split('/')[1]:variables_to_keep_and_rename[variable] for variable in variables_to_keep_and_rename.keys()})\n",
        "\n",
        "# Examine the result:\n",
        "tempo_data_uvai"
      ],
      "metadata": {
        "id": "3doW3wHTKNV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Apply quality control*\n",
        "\n",
        "<details>\n",
        "\n",
        "In this case, we only filter by Solar Zenith Angle (accepting values less than 70)\n",
        "\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "s0RoTzSFJ1yf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filter_sza = tempo_data_uvai['o3_sza'] < 70\n",
        "\n",
        "tempo_data_uvai_filtered = tempo_data_uvai.where(filter_sza).squeeze()"
      ],
      "metadata": {
        "id": "gOR8hYtJK-Qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Plot Maps of UV Aerosol Index*\n",
        "\n",
        "The code below is taken from earlier plotting examples, with slight modifications.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Run the cell and check the output.\n",
        "\n",
        "* Try picking different timestamps to plot and examining the output."
      ],
      "metadata": {
        "id": "BhlKGiT3J5H7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a timestamp to plot:\n",
        "timestamp_local = pd.Timestamp('2025-03-14 14:30:00',tz='America/Chicago')\n",
        "\n",
        "# Convert the timestamp from local time to UTC:\n",
        "timestamp_utc = timestamp_local.tz_convert(tz='UTC').to_datetime64()\n",
        "\n",
        "# Select the data to plot:\n",
        "data_to_plot = tempo_data_uvai_filtered['uv_aerosol_index'].sel(time=timestamp_utc,method='nearest')\n",
        "\n",
        "# Plot the data on a map:\n",
        "fig, ax = plt.subplots(figsize=(10, 6), subplot_kw={\"projection\": data_proj})\n",
        "\n",
        "make_nice_map(ax)\n",
        "\n",
        "data_to_plot.plot(\n",
        "    ax=ax, # axis to add plot to\n",
        "    cmap=plt.get_cmap('pink_r'), # color scale\n",
        "    vmin=-10, # minimum value\n",
        "    vmax=10, # maximum value\n",
        "    cbar_kwargs={'label':'UV Aerosol Index'} # set colorbar label\n",
        ")\n",
        "\n",
        "ax.set_title(timestamp_local)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-hR0z87HLKvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use Aerosol Index to Mask Features for Analysis\n",
        "\n",
        "We will now use the UV Aerosol Index, as a rough indicator of the extent of the smoke plumes, to perform an analysis comparing trace gas concentrations in areas impacted by the smoke plumes with those outside."
      ],
      "metadata": {
        "id": "Q5DSnYiVLy_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine the TEMPO data into a single Dataset\n",
        "\n",
        "To facilitate the analysis, first, combine all the TEMPO Datasets you created into a single Dataset.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Write code which will combine each of the TEMPO Datasets into a single Dataset.\n",
        "\n",
        "<details>\n",
        "\n",
        "*Hint*: To merge multiple datasets together, use the following code example:\n",
        "\n",
        "```\n",
        "combined_dataset = xr.merge([dataset_1,dataset_2,dataset_3])\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "PsxrD4pGMJEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WRITE YOUR CODE HERE"
      ],
      "metadata": {
        "id": "NrshOz5FXam8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a mask based on the UV Aerosol Index\n",
        "\n",
        "Now, we will use the values of the UV Aerosol Index to create a mask, separating the smoke plume from other parts of the scene.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Use the plots of UV Aerosol Index you created above to seelct a value which seems to separate between smoke-impacted and non-smoke-impacted parts of the scene.\n",
        "\n",
        "* Write code which will create a binary mask based on that value.\n",
        "\n",
        "<details>\n",
        "\n",
        "*Hint*: You can create a dataset which acts as a binary mask by setting it equal to a logical expression, such as an inequality. For example:\n",
        "\n",
        "```\n",
        "binary_mask = data > threshold\n",
        "```\n",
        "\n",
        "`binary_mask` will have value `True` wherever the values in `data` are above `threshold`.\n",
        "\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "xKTbJvb4ME_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WRITE YOUR CODE HERE"
      ],
      "metadata": {
        "id": "yTVeSEkWIpSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot the mask\n",
        "\n",
        "Use the plot below to visualize your binary mask.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* Modify the code below as needed to plot values of your binary mask.\n",
        "\n",
        "* Try changing how your mask is defined in the above cell and re-plotting to determine what value of the mask seems reasonable.\n",
        "\n",
        "\n",
        "<details>\n",
        "\n",
        "*Hint*: The code assumes that `tempo_data[uvai_mask]` is the binary mask.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "sihi3FL3M_ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a timestamp to plot:\n",
        "timestamp_local = pd.Timestamp('2025-03-14 14:30:00',tz='America/Chicago')\n",
        "\n",
        "# Convert the timestamp from local time to UTC:\n",
        "timestamp_utc = timestamp_local.tz_convert(tz='UTC').to_datetime64()\n",
        "\n",
        "# Select the data to plot:\n",
        "data_to_plot = tempo_data['uvai_mask'].sel(time=timestamp_utc,method='nearest')\n",
        "\n",
        "# Plot the data on a map:\n",
        "fig, ax = plt.subplots(figsize=(10, 6), subplot_kw={\"projection\": data_proj})\n",
        "\n",
        "make_nice_map(ax)\n",
        "\n",
        "data_to_plot.plot(\n",
        "    ax=ax, # axis to add plot to\n",
        "    cmap=plt.get_cmap('cool'), # color scale\n",
        "    vmin=0, # minimum value\n",
        "    vmax=1, # maximum value\n",
        "    cbar_kwargs={'label':'Mask'} # set colorbar label\n",
        ")\n",
        "\n",
        "ax.set_title(timestamp_local)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SJLk6klyMXMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use the mask to analyze a timeseries\n",
        "\n",
        "We will now use the mask to seperate between smoke-impacted and non-smoke-impacted parts of the scene, and measure the average tropospheric NO2 between these areas.\n",
        "\n",
        "*Instructions*\n",
        "\n",
        "* In the beginning of this cell, write code to define three new data arrays:\n",
        "\n",
        "  * `average_no2_overall` should be the spatial average tropospheric column NO2 across the entire region.\n",
        "\n",
        "  * `average_no2_masked` should be the spatial average in regions where your binary mask for smoke is true.\n",
        "\n",
        "  * `average_no2_unmasked` should be the spatial average in regions where your binary mask for smoke is false.\n",
        "\n",
        "* Use the rest of the code in the cell to create a time-series plot of these three data arrays.\n",
        "\n",
        "* Once you are satisfied, duplicate the cell and repeat the exercise for the Formaldehyde data.\n",
        "\n",
        "<details>\n",
        "\n",
        "*Hint*: To select only data where a mask is true, use this code example:\n",
        "\n",
        "```\n",
        "masked_data = data.where(binary_mask)\n",
        "```\n",
        "\n",
        "*Hint*: To select only data where a mask is false, use this code example:\n",
        "\n",
        "\n",
        "```\n",
        "unmasked_data = data.where(~binary_mask)\n",
        "```\n",
        "\n",
        "*Hint*: To spatially average data, you can take the mean value across the latitude and longitude dimensions, following this example:\n",
        "\n",
        "```\n",
        "spatially_averaged_data = data.mean(['latitude','longitude'])\n",
        "```\n",
        "\n",
        "*Huint*: You can create a new cell to test out new parts of the code you are writing before trying to run the plotting codes.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "qeB6RZPQNHJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "average_no2_overall = # WRITE YOUR CODE HERE\n",
        "average_no2_masked = # WRITE YOUR CODE HERE\n",
        "average_no2_unmasked = # WRITE YOUR CODE HERE\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "\n",
        "average_no2_overall.plot(ax=ax,label='Overall',color='black')\n",
        "average_no2_masked.plot(ax=ax,label='Smoke-Impacted',color='red')\n",
        "average_no2_unmasked.plot(ax=ax,label='Non-Smoke-Impacted',color='blue',linestyle=':')\n",
        "\n",
        "ax.set_ylabel('Tropospheric Column $NO_2$ [$molecules/cm^2$]')\n",
        "ax.set_xlabel('Time')\n",
        "ax.set_ylim(0,20e15)\n",
        "ax.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mY8isZ6cIpKx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}